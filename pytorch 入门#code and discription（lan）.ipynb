{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.8855e-44, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.2948e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "#tensor 与numpy 类似\n",
    "x= torch.empty(5,3)\n",
    "print(x)               #输出一个未初始化的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8940, 0.7068],\n",
      "        [0.3190, 0.7277],\n",
      "        [0.7156, 0.5120],\n",
      "        [0.9176, 0.4257]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(4,2)\n",
    "print(x)                #输出一个随机初始化的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x= torch.zeros(9,4,dtype = torch.long)\n",
    "print(x)               #构建一个指定类型的全零矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "x= torch.tensor([[1,2],\n",
    "                [3,4]])\n",
    "print(x)                   #直接构建给定的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[0.3832, 0.8656, 0.3864],\n",
      "        [0.5323, 0.7087, 0.0353],\n",
      "        [0.5768, 0.6625, 0.7421],\n",
      "        [0.6483, 0.6932, 0.9604],\n",
      "        [0.2241, 0.2615, 0.7546]])\n"
     ]
    }
   ],
   "source": [
    "# 基于存在的矩阵构建矩阵\n",
    "x= torch.ones(5,3,dtype=torch.double)\n",
    "print(x)\n",
    "y=torch.rand_like(x,dtype=torch.float)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#型号？\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.Size 是元组，所以支持元组的所有操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2527, 0.7476, 0.3509],\n",
      "        [0.5930, 0.3191, 0.2139],\n",
      "        [0.8033, 0.9844, 0.3410],\n",
      "        [0.6127, 0.9617, 0.2486],\n",
      "        [0.8758, 0.1481, 0.1172]])\n",
      "tensor([[0.6359, 1.6131, 0.7373],\n",
      "        [1.1253, 1.0278, 0.2492],\n",
      "        [1.3801, 1.6468, 1.0831],\n",
      "        [1.2610, 1.6549, 1.2090],\n",
      "        [1.0999, 0.4097, 0.8718]])\n"
     ]
    }
   ],
   "source": [
    "c=torch.rand(5,3)\n",
    "print(c)\n",
    "print(y+c)         #当y,c不相同时，不能相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6359, 1.6131, 0.7373],\n",
      "        [1.1253, 1.0278, 0.2492],\n",
      "        [1.3801, 1.6468, 1.0831],\n",
      "        [1.2610, 1.6549, 1.2090],\n",
      "        [1.0999, 0.4097, 0.8718]])\n"
     ]
    }
   ],
   "source": [
    "#另一种相加的方式\n",
    "print(torch.add(y,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6359, 1.6131, 0.7373],\n",
      "        [1.1253, 1.0278, 0.2492],\n",
      "        [1.3801, 1.6468, 1.0831],\n",
      "        [1.2610, 1.6549, 1.2090],\n",
      "        [1.0999, 0.4097, 0.8718]])\n"
     ]
    }
   ],
   "source": [
    "result =torch.empty(0,0)\n",
    "torch.add(y,c,out =result)\n",
    "print(result)                #经测验，empty中的（n,m）取值不影响结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6359, 1.6131, 0.7373],\n",
       "        [1.1253, 1.0278, 0.2492],\n",
       "        [1.3801, 1.6468, 1.0831],\n",
       "        [1.2610, 1.6549, 1.2090],\n",
       "        [1.0999, 0.4097, 0.8718]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in_place 计算\n",
    "y.add_(c)\n",
    "#在位计算后加  _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3509, 0.2139, 0.3410, 0.2486, 0.1172])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#索引与numpy类似\n",
    "b=c[:,2]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# resize\n",
    "x=torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z=y.view(-1,8)         #-1的意思是 向量最终维数取决于后者 8\n",
    "print(x.size(),y.size(),z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.2156e+11])\n",
      "-721557651456.0\n"
     ]
    }
   ],
   "source": [
    "#使用。item 将元素转化为Python量\n",
    "x=torch.empty(1)\n",
    "y=x.item()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy 和tensor 之间的转换\n",
    "1.tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x= torch.ones(5)\n",
    "print(x)\n",
    "x.numpy()\n",
    "print(x)\n",
    "b=x.numpy()\n",
    "print(b)                     #说明前一种情况不改变X的原值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "x.add_(1)\n",
    "print(x)\n",
    "print(b)                      #说明b是指向x的，x改变，b亦改变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a= np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(b,1,out=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4., 4., 4., 4., 4.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b.size())    \n",
    "np.add(a,1,out =a)               # 发现了吗？   b是Tensor， 但用numpy去改变b,a也改变了  out 只能是a，说明out得是 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.ones(5)\n",
    "b=torch.ones(4)\n",
    "print(a)\n",
    "print(a.dtype)\n",
    "list(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA tensors\n",
    "#这里暂且搁置                 #询问CUDA的功能和用途"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先放下，看完autograd 写总结\n",
    "# 当给定的tensor的requires_grad 是True的时候，这个tensor的计算将被追踪。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x =torch.ones(2,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y=x+2\n",
    "print(y)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x00000000082331D0>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]], grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x0000000004FA9C18>\n"
     ]
    }
   ],
   "source": [
    "z=y*3\n",
    "print(z)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18., 18.],\n",
      "        [18., 18.]], grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x0000000008233CC0>\n"
     ]
    }
   ],
   "source": [
    "y=y*6\n",
    "print(y)\n",
    "print(y.grad_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "y=x+2\n",
    "z= y*y*3\n",
    "out = z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when no True:\n",
      "False\n",
      "None\n",
      "None\n",
      "when True:\n",
      "True\n",
      "None\n",
      "None\n",
      "when b:\n",
      "True\n",
      "None ?\n",
      "<SumBackward0 object at 0x0000000005555B38> +\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,2)\n",
    "a =(a*3)/(a-1)\n",
    "print(\"when no True:\")\n",
    "print(a.requires_grad)\n",
    "print(a.grad)\n",
    "print(a.grad_fn)\n",
    "a.requires_grad_(True)\n",
    "print(\"when True:\")\n",
    "print(a.requires_grad)\n",
    "print(a.grad)\n",
    "print(a.grad_fn)\n",
    "b=(a*a).sum()\n",
    "print(\"when b:\")\n",
    "print(b.requires_grad)\n",
    "print(b.grad,\"?\")\n",
    "print(b.grad_fn,\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "<built-in method size of Tensor object at 0x00000000055B6B40>\n",
      "out: tensor(27., grad_fn=<MeanBackward1>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# 没看懂为什么最后是4.5，也就是说和是18，那应该是（x+2）*6，为什么？ \n",
    "#这个计算有个很有意思的点，最后除以n*m，为什么不放在中间？\n",
    "x =torch.ones(2,2,requires_grad=True)\n",
    "y=x+2\n",
    "print(\"y:\",y)\n",
    "z= y*y*3\n",
    "out = z.mean()\n",
    "print(z)\n",
    "print(out.size)\n",
    "print(\"out:\",out)\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([[4,6],\n",
    "               [10,12]],dtype=torch.float)\n",
    "z=x.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]], grad_fn=<AddBackward0>)\n",
      "tensor(2., grad_fn=<MeanBackward1>)\n",
      "tensor([[0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(3,3,requires_grad=True)\n",
    "z=x+1\n",
    "print(z)\n",
    "out= z.mean()\n",
    "print(out)\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45., grad_fn=<MeanBackward1>)\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,3,requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 5\n",
    "out = z.mean()\n",
    "#z.backward() #出错，RuntimeError: grad can be implicitly created only for scalar outputs\n",
    "out.backward()\n",
    "print(out)\n",
    "print(x.grad)\n",
    "# 多次运行该段程序，x.grad会每次增大5，out不变。为什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.ones(2,2,requires_grad =True)\n",
    "z= x+2\n",
    "z=z.mean()\n",
    "z.backward()            #说明backward只能是标量输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,2,requires_grad=True)\n",
    "y= x+2\n",
    "y.backward(torch.ones(2,2),retain_graph=True)           #这一步的作用是什么？\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient: tensor([[-0.2301, -1.2776],\n",
      "        [-0.2416, -0.2475]])\n",
      "tensor([[ 0.6527,  0.6595],\n",
      "        [ 0.6687, -0.7312]])\n"
     ]
    }
   ],
   "source": [
    "gradient = torch.randn(2,2)\n",
    "print(\"gradient:\",gradient)\n",
    "y.backward(gradient)                       #这一步的运行原理是什么？\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
